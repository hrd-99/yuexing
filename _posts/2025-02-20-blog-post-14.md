---

title: 'I/O'
date: 2024-10-22
permalink: /posts/2025/02/blog-post-14/
tags:
  - go
excerpt: ""  # 这里设置为空，阻止预览
---

### **I/O 的类型**

1. **磁盘 I/O**：
   - 读写文件（如读取日志、写入数据库）。
   - 示例：`fread()`、`fwrite()`。
2. **网络 I/O**：
   - 发送或接收网络数据（如 HTTP 请求、TCP 连接）。
   - 示例：`send()`、`recv()`。
3. **设备 I/O**：
   - 与硬件设备交互（如打印机、传感器）。
   - 示例：`ioctl()`。
4. **内存 I/O**：
   - 内存与 CPU 之间的数据传输（如内存映射文件）。
   - 示例：`mmap()`。





------

### **关键对比**

|      模型      | 阻塞？ | 同步？ | 线程开销 | 编程复杂度 | 性能 |     典型应用     |
| :------------: | :----: | :----: | :------: | :--------: | :--: | :--------------: |
|   阻塞式 I/O   |   是   |  同步  |    高    |     低     |  低  |     简单脚本     |
|  非阻塞式 I/O  |   否   |  同步  |    中    |     中     |  中  |     轮询场景     |
|  I/O 多路复用  |  是*   |  同步  |    低    |     高     |  高  |   Nginx、Redis   |
|  信号驱动 I/O  |   否   |  异步  |    低    |     高     |  中  |     特殊需求     |
| 异步 I/O (AIO) |   否   |  异步  |   最低   |    最高    | 最高 | 大规模并发服务器 |

> *注：I/O 多路复用中，`select`/`epoll` 调用本身是阻塞的，但线程可以同时处理多个 I/O。

一个进程虽然任一时刻只能处理一个请求，但是处理每个请求的事件时，耗时控制在 1 毫秒以内，这样 1 秒内就可以处理上千个请求，把时间拉长来看，多个请求复用了一个进程，这就是多路复用，这种思想很类似一个 CPU 并发多个进程，所以也叫做时分多路复用。 我们熟悉的 select/poll/epoll 内核提供给用户态的多路复用系统调用，进程可以通过一个系统调用函数从内核中获取多个事件。

`select`、`poll` 和 `epoll` 是 Linux 系统中用于实现 **I/O 多路复用** 的三种机制。它们允许一个线程同时监控多个文件描述符（如 Socket、管道等），并在某个描述符就绪时通知程序进行处理。



|        特性        |     select     |      poll      |      epoll       |
| :----------------: | :------------: | :------------: | :--------------: |
|   **跨平台支持**   |       是       |       是       |     仅 Linux     |
| **文件描述符数量** |   默认 1024    |     无限制     |      无限制      |
|      **效率**      |   低（O(n)）   |   中（O(n)）   |    高（O(1)）    |
|  **事件通知方式**  | 遍历所有描述符 | 遍历所有描述符 | 仅通知就绪描述符 |
|    **适用场景**    |   低并发场景   |  中等并发场景  |    高并发场景    |

select 和 poll 并没有本质区别，它们内部都是使用「线性结构」来存储进程关注的 Socket 集合。 



在使用的时候，首先需要把关注的 Socket 集合通过 select/poll 系统调用从用户态拷贝到内核态，然后由内核检测事件，当有网络事件产生时，内核需要遍历进程关注 Socket 集合，找到对应的 Socket，并设置其状态为可读/可写，然后把整个 Socket 集合从内核态拷贝到用户态，用户态还要继续遍历整个 Socket 集合找到可读/可写的 Socket，然后对其处理。 

很明显发现，select 和 poll 的缺陷在于，当客户端越多，也就是 Socket 集合越大，Socket 集合的遍历和拷贝会带来很大的开销，因此也很难应对 C10K。 epoll 是解决 C10K 问题的利器，通过两个方面解决了 select/poll 的问题。 epoll 在内核里使用「红黑树」来关注进程所有待检测的 Socket，红黑树是个高效的数据结构，增删改一般时间复杂度是 O(logn)，通过对这棵黑红树的管理，不需要像 select/poll 在每次操作时都传入整个 Socket 集合，减少了内核和用户空间大量的数据拷贝和内存分配。

 epoll 使用事件驱动的机制，内核里维护了一个「链表」来记录就绪事件，只将有事件发生的 Socket 集合传递给应用程序，不需要像 select/poll 那样轮询扫描整个集合（包含有和无事件的 Socket ），大大提高了检测的效率。 而且，epoll 支持边缘触发和水平触发的方式，而 select/poll 只支持水平触发，一般而言，边缘触发的方式会比水平触发的效率高。



|     特性     |    水平触发（Level-Triggered）     |      边缘触发（Edge-Triggered）      |
| :----------: | :--------------------------------: | :----------------------------------: |
| **通知时机** |    描述符处于就绪状态时持续通知    | 描述符状态从非就绪变为就绪时通知一次 |
| **处理方式** | 可部分处理数据，剩余数据会继续通知 |       必须一次性处理完所有数据       |
| **适用场景** |     对事件处理时间不确定的场景     |          高并发、高性能场景          |
| **实现支持** | `select`、`poll`、`epoll`（默认）  |   `epoll`（需显式设置 `EPOLLET`）    |

**零拷贝（Zero-Copy）** 是一种优化技术，旨在减少数据在内核空间和用户空间之间的复制次数，从而提升数据传输效率，降低 CPU 和内存的开销。
